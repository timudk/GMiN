{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful resources:\n",
    "1. https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html#vae-variational-autoencoder\n",
    "2. https://arxiv.org/pdf/1606.05908.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic model\n",
    "Variational autoencoder are based on the principles of variational inference and graphical models. We want to generate data $x \\in \\mathcal{X}$; to do so we first split the joint probability of observable and latent variables into prior and likelihood\n",
    "\\begin{align}\n",
    "    p(x,z) = p(x \\mid z) p(z).\n",
    "\\end{align}\n",
    "If we have many latent variables, marginalization of the joint probability distribution is intractable. \n",
    "#### Model assumption and loss function\n",
    "In order to make the marginalization tractable, we model the posterior probability as \n",
    "\\begin{align}\n",
    "    q_{\\phi}(z \\mid x) \\approx p(z \\mid x).\n",
    "\\end{align}\n",
    "Obviously, we want the model to be very close to $p(z \\mid x)$; a measure of closeness is given by the Kullback--Leibler divergence \n",
    "\\begin{align}\n",
    "    D_{\\text{KL}}(q_\\phi || p) &= \\int q_\\phi \\log \\frac{q_\\phi}{p} \\, dx \\\\\n",
    "                                 &= \\int q_\\phi \\log \\frac{q_\\phi p(x)}{p(x,z)} \\, dx \\\\\n",
    "                                 &= \\log p(x) + \\int q_\\phi \\log \\frac{q_\\phi}{p(x \\mid z) p(z)} \\, dx \\\\   \n",
    "                                 &= \\log p(x) + D_{\\text{KL}}(q_\\phi || p(z)) - \\mathbb{E}_{q_\\phi}(p(x \\mid z)).\n",
    "\\end{align}\n",
    "Since we want to minimize, both, the negative log likelihood $- \\log p(x)$ as well as the difference between $q_\\phi$ and $p(z \\mid x)$, we the loss of our model to\n",
    "\\begin{align}\n",
    "    L_{\\text{VAE}} &= - \\log p(x) + D_{\\text{KL}}(q_\\phi || p) \\\\\n",
    "                   &= \\underbrace{D_{\\text{KL}}(q_\\phi || p(z)) - \\mathbb{E}_{q_\\phi}(p(x \\mid z))}_{\\text{Evidence lower bound (ELBO)}}. \\quad \\text{(using equation above)}\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
